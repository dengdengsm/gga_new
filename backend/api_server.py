import json
import os
import shutil
import uvicorn
from fastapi import FastAPI, UploadFile, File, Form, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.concurrency import run_in_threadpool
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import glob
import re
from datetime import datetime
import time
import uuid

# --- å¼•å…¥ä½ çš„æ ¸å¿ƒæ¨¡å— ---
from router import RouterAgent
from graphrag import LightGraphRAG
from codez_gen import CodeGenAgent
from code_revise import CodeReviseAgent
from utils import quick_validate_mermaid, preprocess_multi_files
from document_reader import DocumentAnalyzer
from project_manager import ProjectManager

# --- é…ç½® ---
PROJECTS_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.projects"))
DEFAULT_PROJECT = "default"

# --- å…¨å±€é¡¹ç›®ç®¡ç†å™¨ ---

project_manager = ProjectManager(DEFAULT_PROJECT,PROJECTS_ROOT)

# --- åˆå§‹åŒ– FastAPI ---
app = FastAPI(title="Smart Mermaid Backend (Project Managed)")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- 1. åˆå§‹åŒ– Agents ---
print("ğŸš€ [Backend] æ­£åœ¨å¯åŠ¨åç«¯å¼•æ“ï¼ŒåŠ è½½ Agents...")
default_graph_db = os.path.join(project_manager.get_project_dir(DEFAULT_PROJECT), "graph_db")

try:
    rag_engine = LightGraphRAG(persist_dir=default_graph_db)
    router_agent = RouterAgent(model_name="deepseek-chat", learn_mode=False)
    code_gen_agent = CodeGenAgent(model_name="deepseek-chat")
    code_revise_agent = CodeReviseAgent(
        mistake_file_path="./knowledge/experience/mistakes.json", 
        model_name="deepseek-chat"
    )
    doc_analyzer = DocumentAnalyzer() 
    print("âœ… [Backend] å¼•æ“åŠ è½½å®Œæ¯•ï¼")
except Exception as e:
    print(f"âŒ [Backend] å¼•æ“åŠ è½½å¤±è´¥: {e}")


# --- ä»»åŠ¡çŠ¶æ€ç®¡ç† ---
tasks = {}

def process_upload_background(task_id: str, file_location: str, project_name: str):
    """åå°ä»»åŠ¡ï¼šå¤„ç†æ–‡ä»¶å¹¶æ„å»ºå›¾è°±"""
    time.sleep(2) 
    
    try:
        tasks[task_id] = {"status": "processing", "message": "æ–‡ä»¶å·²æ¥æ”¶..."}
        project_manager.update_file_status(task_id, "uploaded", "ç­‰å¾…ç”Ÿæˆæ—¶å¤„ç†")
        
        print(f"ğŸ”„ [Task {task_id}] æ–‡ä»¶å·²å°±ç»ª: {os.path.basename(file_location)}")
        
        # æ³¨æ„ï¼šä¸å†æ­¤å¤„è‡ªåŠ¨æ„å»ºå›¾è°±ï¼Œè€Œæ˜¯æ¨è¿Ÿåˆ°ç”Ÿæˆé˜¶æ®µç»Ÿä¸€å¤„ç†å¤šæ–‡ä»¶
        
        tasks[task_id] = {"status": "success", "message": "æ–‡ä»¶å°±ç»ª"}
        project_manager.update_file_status(task_id, "success", "æ–‡ä»¶å°±ç»ª")
        
    except Exception as e:
        tasks[task_id] = {"status": "error", "message": str(e)}
        project_manager.update_file_status(task_id, "error", str(e))
        print(f"âŒ [Task {task_id}] å¤„ç†å¤±è´¥: {e}")


# --- 2. Request Models ---

class GenerateRequest(BaseModel):
    text: str
    diagramType: str = "auto"
    aiConfig: Optional[Dict[str, Any]] = None
    useGraph: bool = True 
    useFileContext: bool = True # æ˜¯å¦ä½¿ç”¨æ–‡ä»¶ä¸Šä¸‹æ–‡
    richness:float = 0.5

class FixRequest(BaseModel):
    mermaidCode: str
    errorMessage: str

class PasswordRequest(BaseModel):
    password: str

class ConfigUpdateRequest(BaseModel):
    apiKey: str
    apiUrl: str
    modelName: str

class ProjectCreateRequest(BaseModel):
    name: str

class ProjectSwitchRequest(BaseModel):
    name: str

class HistoryEntry(BaseModel):
    id: Optional[str] = None
    query: str
    code: str
    diagramType: str = "auto"
    timestamp: Optional[str] = None

class OptimizeRequest(BaseModel):
    code: str
    instruction: str
    aiConfig: Optional[Dict[str, Any]] = None
    accessPassword: Optional[str] = None
    selectedModel: Optional[str] = None
# --- 3. Routes ---

# === é¡¹ç›®ç®¡ç†æ¥å£ ===

@app.get("/api/projects")
async def list_projects():
    return {
        "projects": project_manager.list_projects(), 
        "current": project_manager.current_project
    }

@app.post("/api/projects")
async def create_project(req: ProjectCreateRequest):
    if not re.match(r'^[a-zA-Z0-9_-]+$', req.name):
        return {"status": "error", "message": "é¡¹ç›®åç§°åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦"}
    
    if req.name in project_manager.list_projects():
        return {"status": "error", "message": "é¡¹ç›®å·²å­˜åœ¨"}
    
    project_manager.ensure_project_exists(req.name)
    return {"status": "success", "message": f"é¡¹ç›® {req.name} å·²åˆ›å»º"}

@app.post("/api/projects/switch")
async def switch_project(req: ProjectSwitchRequest):
    try:
        if req.name == project_manager.current_project:
            return {"status": "success", "current": req.name, "message": "Already on this project"}

        new_dir = project_manager.switch_project(req.name)
        print(f"ğŸ”„ [Project] åˆ‡æ¢è‡³: {req.name}")
        
        new_graph_db = os.path.join(new_dir, "graph_db")
        rag_engine.reload_db(new_graph_db)
        
        return {"status": "success", "current": req.name}
    except Exception as e:
        return {"status": "error", "message": str(e)}

# === æ–‡ä»¶åˆ—è¡¨æ¥å£ ===
@app.get("/api/files")
async def list_files():
    return project_manager.get_file_records()

@app.delete("/api/files/{file_id}")
async def delete_file(file_id: str):
    project_manager.remove_file_record(file_id)
    return {"status": "success"}

# === å›¾è°±æ•°æ®æ¥å£ ===
@app.get("/api/graph/data")
async def get_graph_data():
    return rag_engine.get_graph_snapshot()

# === å†å²è®°å½•æ¥å£ ===

@app.get("/api/history")
async def get_history():
    p_dir = project_manager.get_project_dir()
    hist_file = os.path.join(p_dir, "history.json")
    try:
        if os.path.exists(hist_file):
            with open(hist_file, "r", encoding="utf-8") as f:
                return json.load(f)
        return []
    except Exception:
        return []

@app.post("/api/history")
async def add_history(entry: HistoryEntry):
    p_dir = project_manager.get_project_dir()
    hist_file = os.path.join(p_dir, "history.json")
    
    new_item = entry.dict()
    if not new_item.get("id"):
        new_item["id"] = str(int(time.time() * 1000))
    if not new_item.get("timestamp"):
        new_item["timestamp"] = datetime.now().isoformat()
        
    try:
        current_data = []
        if os.path.exists(hist_file):
            with open(hist_file, "r", encoding="utf-8") as f:
                try: current_data = json.load(f)
                except: current_data = []
        
        current_data.insert(0, new_item)
        
        with open(hist_file, "w", encoding="utf-8") as f:
            json.dump(current_data, f, ensure_ascii=False, indent=2)
            
        return {"status": "success", "entry": new_item}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@app.delete("/api/history/{entry_id}")
async def delete_history(entry_id: str):
    p_dir = project_manager.get_project_dir()
    hist_file = os.path.join(p_dir, "history.json")
    try:
        if os.path.exists(hist_file):
            with open(hist_file, "r", encoding="utf-8") as f:
                data = json.load(f)
            new_data = [item for item in data if item.get("id") != entry_id]
            with open(hist_file, "w", encoding="utf-8") as f:
                json.dump(new_data, f, ensure_ascii=False, indent=2)
        return {"status": "success"}
    except Exception as e:
        return {"status": "error", "message": str(e)}
    
@app.delete("/api/history")
async def clear_history():
    p_dir = project_manager.get_project_dir()
    hist_file = os.path.join(p_dir, "history.json")
    try:
        with open(hist_file, "w", encoding="utf-8") as f:
            json.dump([], f)
        return {"status": "success"}
    except Exception as e:
        return {"status": "error", "message": str(e)}

# === ç³»ç»Ÿé…ç½®æ¥å£ ===
@app.post("/api/system/config")
async def update_system_config(config: ConfigUpdateRequest):
    print(f"ğŸ”„ [System] æ”¶åˆ°é…ç½®æ›´æ–°è¯·æ±‚: {config.modelName} @ {config.apiUrl}")
    try:
        config_dict = config.dict()
        if 'router_agent' in globals(): router_agent.reload_llm_config(config_dict)
        if 'code_gen_agent' in globals(): code_gen_agent.reload_llm_config(config_dict)
        if 'code_revise_agent' in globals(): code_revise_agent.reload_llm_config(config_dict)
        return {"status": "success", "message": "AIé…ç½®å·²çƒ­æ›´æ–°"}
    except Exception as e:
        return {"status": "error", "message": str(e)}

# === æ–‡ä»¶ä¸Šä¼ æ¥å£ ===

@app.post("/api/upload")
async def upload_file(
    background_tasks: BackgroundTasks, 
    file: UploadFile = File(...),
    autoBuild: bool = Form(True) 
):
    try:
        upload_dir = os.path.join(project_manager.get_project_dir(), "uploads")
        os.makedirs(upload_dir, exist_ok=True)
        
        file_location = os.path.join(upload_dir, file.filename)
        
        with open(file_location, "wb") as f:
            while True:
                chunk = await file.read(1024 * 1024)
                if not chunk:
                    break
                await run_in_threadpool(f.write, chunk)
            
        task_id = str(uuid.uuid4())
        print(f"ğŸ“‚ [Upload] æ”¶åˆ°æ–‡ä»¶: {file.filename}, ID: {task_id}, AutoBuild: {autoBuild}")
        
        initial_status = "pending" if autoBuild else "uploaded"
        initial_msg = "æ–‡ä»¶ç­‰å¾…å¤„ç†..." if autoBuild else "æ–‡ä»¶å·²ä¿å­˜ (å¾…åˆ†æ)"
        
        tasks[task_id] = {
            "status": initial_status,
            "message": initial_msg,
            "filename": file.filename,
            "timestamp": time.time(),
            "location": file_location 
        }
        
        file_record = {
            "id": task_id,
            "filename": file.filename,
            "status": initial_status,
            "message": initial_msg,
            "timestamp": datetime.now().isoformat(),
            "location": file_location, 
            "size": 0 
        }
        project_manager.add_file_record(file_record)
        
        if autoBuild:
            background_tasks.add_task(
                process_upload_background, 
                task_id, 
                file_location, 
                project_manager.current_project
            )
        
        return {
            "status": "success", 
            "message": "æ–‡ä»¶ä¸Šä¼ æˆåŠŸ" + ("ï¼Œå·²è¿›å…¥å¤„ç†é˜Ÿåˆ—" if autoBuild else "ï¼Œç­‰å¾…ä½¿ç”¨"),
            "taskId": task_id,
            "filename": file.filename
        }
    except Exception as e:
        print(f"ğŸ”¥ Upload Error: {e}")
        return {"status": "error", "message": str(e)}

@app.get("/api/tasks/{task_id}")
async def get_task_status(task_id: str):
    task = tasks.get(task_id)
    if not task:
        return {"status": "error", "message": "ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ"}
    return task

# === æ ¸å¿ƒç”Ÿæˆæ¥å£ (å¢å¼ºç‰ˆï¼šæ”¯æŒå¤šæ–‡ä»¶åˆ†è·¯å¤„ç†) ===
@app.post("/api/generate-mermaid")
async def generate_mermaid(request: GenerateRequest):
    user_query = request.text
    use_graph = request.useGraph
    diagram_type = request.diagramType
    use_file = request.useFileContext
    
    print(f"\nâš¡ [Generate] æ”¶åˆ°è¯·æ±‚: {user_query[:50]}... | Graph: {use_graph} | File: {use_file}")

    try:
        context = ""
        project_dir = project_manager.get_project_dir()
        upload_dir = os.path.join(project_dir, "uploads")
        
        # 1. é¢„å¤„ç†æ–‡ä»¶ï¼šè‡ªåŠ¨åˆ†ç±»ä¸åˆå¹¶
        # merged_md: æ–‡æœ¬ç±»æ–‡ä»¶çš„åˆå¹¶å†…å®¹è·¯å¾„ (ç”¨äº GraphRAG)
        # text_files: æ–‡æœ¬æ–‡ä»¶åˆ—è¡¨ (ç”¨äº No-Graph ç›´æ¥è¯»å–)
        # blob_files: éæ–‡æœ¬æ–‡ä»¶åˆ—è¡¨ (ç”¨äº DocumentAnalyzer)
        merged_md, text_files, blob_files = preprocess_multi_files(upload_dir, project_dir)
        total_files_count = len(text_files) + len(blob_files)

        if use_file and total_files_count > 0:
            
            # --- åˆ†æ”¯ A: çŸ¥è¯†å›¾è°±æ¨¡å¼ (GraphRAG) ---
            if use_graph:
                print("   -> ğŸ”µ Mode: GraphRAG (Full Context Integration)")
                
                # 1. å‡†å¤‡å›¾è°±æ„å»ºçš„å®Œæ•´è¯­æ–™ (æ–‡æœ¬æ–‡ä»¶ + éæ–‡æœ¬æ–‡ä»¶çš„AIæè¿°)
                full_corpus_content = ""
                
                # A. è¯»å–ç°æœ‰çš„åˆå¹¶æ–‡æœ¬ (æ¥è‡ª text_files)
                if merged_md and os.path.exists(merged_md):
                    with open(merged_md, "r", encoding="utf-8") as f:
                        full_corpus_content += f.read() + "\n\n"
                
                # B. å¤„ç†éæ–‡æœ¬æ–‡ä»¶ (Blob) -> è½¬ä¸ºæ–‡æœ¬æè¿°
                # é€»è¾‘è¦æ±‚ï¼šæ¯ä¸ªéæ–‡æœ¬æ–‡ä»¶ç”Ÿæˆ 1200 token çš„è¯¦ç»†è¯´æ˜
                if blob_files:
                    print(f"   -> [GraphPrep] æ­£åœ¨å°† {len(blob_files)} ä¸ªéæ–‡æœ¬æ–‡ä»¶è½¬åŒ–ä¸ºå›¾è°±è¯­æ–™...")
                    for bf in blob_files:
                        try:
                            # è§†ä½œæ–‡æœ¬æ–‡ä»¶å¤„ç†ï¼šç”Ÿæˆé•¿æè¿°
                            blob_desc = doc_analyzer.analyze(
                                bf, 
                                prompt="è¯·è¯¦ç»†æè¿°è¯¥æ–‡ä»¶çš„å†…å®¹ï¼Œä»¥ä¾¿æ„å»ºå‡†ç¡®çš„çŸ¥è¯†å›¾è°±ã€‚", 
                                max_token_limit=1200
                            )
                            full_corpus_content += f"### File: {os.path.basename(bf)}\nContent Description:\n{blob_desc}\n\n"
                        except Exception as e:
                            print(f"   âŒ Error processing blob {bf} for graph: {e}")
                
                # C. ä¿å­˜ä¸ºä¸´æ—¶æ„å»ºæ–‡ä»¶å¹¶æ„å»ºå›¾è°±
                # å°†æ‰€æœ‰å†…å®¹æ•´åˆåï¼Œå†æ¬¡ç›´æ¥è°ƒç”¨ Build_graph
                graph_input_path = os.path.join(upload_dir, "graph_full_context.md")
                with open(graph_input_path, "w", encoding="utf-8") as f:
                    f.write(full_corpus_content)
                
                try:
                    print(f"   -> Building Graph from integrated corpus: {os.path.basename(graph_input_path)}")
                    rag_engine.build_graph(graph_input_path)
                    print("   âœ… Graph Build/Update Complete")
                except Exception as build_e:
                    print(f"   âŒ Graph Build Failed: {build_e}")
                
                # D. æœç´¢å›¾è°±è·å–ä¸Šä¸‹æ–‡ (Router ä½¿ç”¨çš„å†…å®¹)
                print("   -> Searching Knowledge Graph...")
                context = rag_engine.search(user_query, top_k=3)

            # --- åˆ†æ”¯ B: ç›´æ¥å¤šæ–‡ä»¶æ¨¡å¼ (No Graph) ---
            else:
                print("   -> ğŸŸ  Mode: Direct Analysis (All Files)")
                
                # é€»è¾‘è¦æ±‚ï¼šè°ƒç”¨ document-reader å¤„ç†æ‰€æœ‰æ–‡ä»¶ (å«æ–‡æœ¬æ–‡ä»¶)
                # çº¦æŸï¼šæ€»å­—æ•° (Total Token Budget) 1200
                
                all_targets = text_files + blob_files
                count = len(all_targets)
                token_budget = 1200
                # åŠ¨æ€åˆ†é…æ¯ä¸ªæ–‡ä»¶çš„é…é¢ï¼Œæœ€å°‘ç»™100ï¼Œé˜²æ­¢æ–‡ä»¶è¿‡å¤šæ—¶åˆ†é…ä¸º0
                limit_per_file = max(100, token_budget // count) if count > 0 else 1200
                
                file_contexts = []
                print(f"   -> Processing {count} files (Limit: ~{limit_per_file} tokens/file)...")
                
                for fpath in all_targets:
                    try:
                        # ç»Ÿä¸€ä½¿ç”¨ analyzer ç”Ÿæˆæ‘˜è¦ï¼Œæ–‡æœ¬æ–‡ä»¶ä¹Ÿèƒ½å¤„ç†
                        analysis = doc_analyzer.analyze(
                            fpath, 
                            prompt=f"Briefly explain this file's relevance to: {user_query}", 
                            max_token_limit=limit_per_file
                        )
                        print("æ–‡æ¡£æå–æˆåŠŸ......")
                        file_contexts.append(f"### File: {os.path.basename(fpath)}\nSummary:\n{analysis}\n")
                    except Exception as e:
                        print(f"Error analyzing {fpath}: {e}")
                
                context = "\n".join(file_contexts)
        
        else:
            print("   -> âšª Mode: Pure Text (No File Context)")
            context = "" # ä»…ä½¿ç”¨ç”¨æˆ· Query

        # 2. Router è°ƒåº¦ä¸­å¿ƒ
        print("   -> Router æ­£åœ¨åˆ¶å®šç­–ç•¥...")
        
        if diagram_type == "auto":
            # è‡ªåŠ¨é€‰å‹æ¨¡å¼
            route_res = router_agent.route_and_analyze(user_content=context, user_target=user_query)
        else:
            # å®šå‘ç”Ÿæˆæ¨¡å¼
            print(f"   -> ç”¨æˆ·å¼ºåˆ¶æŒ‡å®šç±»å‹: {diagram_type}")
            route_res = router_agent.analyze_specific_mode(
                user_content=context, 
                user_target=user_query, 
                specific_type=diagram_type
            )
            
        prompt_file = route_res.get("target_prompt_file", "flowchart.md")
        logic_analysis = route_res.get("analysis_content", "")
        
        print(f"   -> ç›®æ ‡ Prompt: {prompt_file}")
        
        # 3. ä»£ç ç”Ÿæˆ
        print("   -> æ­£åœ¨ç”Ÿæˆä»£ç ...")
        initial_code = code_gen_agent.generate_code(logic_analysis, prompt_file=prompt_file,richness=request.richness)
        
        # 4. å¾ªç¯ä¿®å¤é€»è¾‘ (ä¿æŒä¸å˜)
        current_code = initial_code
        max_retries = 3 
        attempt_history = []
        validation = {'valid': False, 'error': 'Not started'}

        print(f"   -> æ­£åœ¨æ ¡éªŒä»£ç è¯­æ³• (æœ€å¤§é‡è¯• {max_retries} æ¬¡)...")

        for i in range(max_retries + 1):
            print(f"   ğŸ” [ç¬¬ {i+1} æ¬¡æ ¡éªŒ] ...")
            validation = quick_validate_mermaid(current_code)
            
            if validation['valid']:
                print("   âœ… æ ¡éªŒé€šè¿‡")
                
                if i > 0 and len(attempt_history) > 0 and code_revise_agent:
                    try:
                        last_fail = attempt_history[-1]
                        code_revise_agent.record_mistake(last_fail["code"], last_fail["error"], current_code)
                        print("   ğŸ“š é”™è¯¯ä¿®å¤ç»éªŒå·²å½•å…¥")
                    except Exception as e:
                        print(f"   âš ï¸ ç»éªŒå½•å…¥å¤±è´¥: {e}")
                
                try: 
                    if router_agent: router_agent.learn_from_success(user_query, current_code)
                except: pass
                
                break 
            
            else:
                error_msg = validation['error']
                print(f"   âŒ æ ¡éªŒå¤±è´¥: {error_msg[:50]}...")
                
                if i == max_retries:
                    break
                
                attempt_history.append({"code": current_code, "error": error_msg})
                
                if code_revise_agent:
                    print(f"   ğŸ”§ å¯åŠ¨è‡ªåŠ¨ä¿®å¤ (ç¬¬ {i+1} æ¬¡å°è¯•)...")
                    current_code = code_revise_agent.revise_code(
                        current_code, 
                        error_message=error_msg, 
                        previous_attempts=attempt_history
                    )
                else:
                    print("   âš ï¸ CodeReviseAgent æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œä¿®å¤")
                    break
        
        final_code = current_code
        final_error = validation['error'] if not validation['valid'] else None

        return {"mermaidCode": final_code, "error": final_error}

    except Exception as e:
        print(f"ğŸ”¥ [Generate] å¤„ç†å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return {"mermaidCode": "", "error": str(e)}

@app.post("/api/optimize-mermaid")
async def optimize_mermaid(request: OptimizeRequest):
    print(f"\nâš¡ [Optimize] æ”¶åˆ°ä¼˜åŒ–è¯·æ±‚: {request.instruction[:50]}...")
    
    try:
        # 2. ç¬¬ä¸€æ­¥ï¼šæ‰§è¡Œä¼˜åŒ– (ä¸æŸ¥ RAGï¼Œçº¯ LLM ä¿®æ”¹)
        # è¿™å¯¹åº”ä½ è¦æ±‚çš„â€œè°ƒç”¨llmè¿›è¡Œä¼˜åŒ–ï¼Œè¿™ä¸ªè¿‡ç¨‹ä¸æ£€ç´¢ä»»ä½•ragâ€
        current_code = code_revise_agent.optimize_code(request.code, request.instruction)
        
        # 3. ç¬¬äºŒæ­¥ï¼šè¿›å…¥æ ‡å‡†çš„â€œæ ¡éªŒ+è‡ªåŠ¨ä¿®å¤â€å¾ªç¯ (å¤ç”¨ generate_mermaid çš„é€»è¾‘)
        # è¿™å¯¹åº”ä½ è¦æ±‚çš„â€œå†ç”¨å’Œgenerate_mermaidåŒä¸€å¥—çš„reviseé€»è¾‘â€
        
        max_retries = 3
        attempt_history = []
        validation = {'valid': False, 'error': 'Not started'}
        
        print(f"   -> æ­£åœ¨æ ¡éªŒä¼˜åŒ–åçš„ä»£ç  (æœ€å¤§é‡è¯• {max_retries} æ¬¡)...")

        for i in range(max_retries + 1):
            validation = quick_validate_mermaid(current_code)
            
            if validation['valid']:
                print(f"   âœ… [ç¬¬ {i+1} æ¬¡] æ ¡éªŒé€šè¿‡")
                # å¦‚æœæ˜¯åœ¨ä¿®å¤è¿‡ç¨‹ä¸­æˆåŠŸçš„ï¼Œè®°å½•ç»éªŒ
                if i > 0 and len(attempt_history) > 0:
                    try:
                        last_fail = attempt_history[-1]
                        code_revise_agent.record_mistake(last_fail["code"], last_fail["error"], current_code)
                    except: pass
                break
            else:
                error_msg = validation['error']
                print(f"   âŒ [ç¬¬ {i+1} æ¬¡] æ ¡éªŒå¤±è´¥: {error_msg[:50]}...")
                
                if i == max_retries:
                    break
                
                attempt_history.append({"code": current_code, "error": error_msg})
                
                # è°ƒç”¨å¸¦ RAG çš„ä¿®å¤åŠŸèƒ½
                print(f"   ğŸ”§ å¯åŠ¨è‡ªåŠ¨ä¿®å¤...")
                current_code = code_revise_agent.revise_code(
                    current_code, 
                    error_message=error_msg, 
                    previous_attempts=attempt_history
                )

        final_error = validation['error'] if not validation['valid'] else None
        
        return {
            "optimizedCode": current_code, 
            "error": final_error
        }

    except Exception as e:
        print(f"ğŸ”¥ [Optimize] å¤„ç†å¼‚å¸¸: {e}")
        return {"optimizedCode": request.code, "error": str(e)}

@app.post("/api/fix-mermaid")
async def fix_mermaid(request: FixRequest):
    
     # === å¾ªç¯ä¿®å¤é€»è¾‘å¼€å§‹ ===
        current_code = request.mermaidCode
        max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
        attempt_history = []
        validation = {'valid': False, 'error': 'Not started'}

        print(f"   -> æ­£åœ¨æ ¡éªŒä»£ç è¯­æ³• (æœ€å¤§é‡è¯• {max_retries} æ¬¡)...")

        for i in range(max_retries + 1):
            print(f"   ğŸ” [ç¬¬ {i+1} æ¬¡æ ¡éªŒ] ...")
            validation = quick_validate_mermaid(current_code)
            
            if validation['valid']:
                print("   âœ… æ ¡éªŒé€šè¿‡")
                
                # å¦‚æœç»å†è¿‡ä¿®å¤ï¼Œè®°å½•ç»éªŒ (Mistake Learning)
                if i > 0 and len(attempt_history) > 0 and code_revise_agent:
                    try:
                        last_fail = attempt_history[-1]
                        code_revise_agent.record_mistake(last_fail["code"], last_fail["error"], current_code)
                        print("   ğŸ“š é”™è¯¯ä¿®å¤ç»éªŒå·²å½•å…¥")
                    except Exception as e:
                        print(f"   âš ï¸ ç»éªŒå½•å…¥å¤±è´¥: {e}")
                
                
                break # æˆåŠŸï¼Œè·³å‡ºå¾ªç¯
            
            else:
                # æ ¡éªŒå¤±è´¥
                error_msg = validation['error']
                print(f"   âŒ æ ¡éªŒå¤±è´¥: {error_msg[:50]}...")
                
                if i == max_retries:
                    print("   âŒ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ”¾å¼ƒè‡ªåŠ¨ä¿®å¤")
                    break
                
                # è®°å½•å¤±è´¥å†å²ï¼Œä¾›ä¸‹æ¬¡ä¿®å¤å‚è€ƒ
                attempt_history.append({
                    "code": current_code,
                    "error": error_msg
                })
                
                if code_revise_agent:
                    print(f"   ğŸ”§ å¯åŠ¨è‡ªåŠ¨ä¿®å¤ (ç¬¬ {i+1} æ¬¡å°è¯•)...")
                    # å…³é”®ï¼šä¼ å…¥ previous_attempts å†å²è®°å½•
                    current_code = code_revise_agent.revise_code(
                        current_code, 
                        error_message=error_msg, 
                        previous_attempts=attempt_history
                    )
                else:
                    print("   âš ï¸ CodeReviseAgent æœªåŠ è½½ï¼Œæ— æ³•è¿›è¡Œä¿®å¤")
                    break
        
        final_code = current_code
        # å¦‚æœæœ€åè¿˜æ˜¯ invalidï¼Œä¿ç•™é”™è¯¯ä¿¡æ¯ä¼ ç»™å‰ç«¯
        final_error = validation['error'] if not validation['valid'] else None

        return {"fixedCode": final_code, "error": final_error}

@app.get("/api/models")
async def get_models():
    return {
        "success": True,
        "models": [
            {"id": "deepseek-chat", "name": "DeepSeek V3 (Server)", "description": "Backend Default"},
            {"id": "deepseek-reasoner", "name": "DeepSeek R1 (Reasoning)", "description": "High Intelligence"}
        ]
    }

@app.post("/api/verify-password")
async def verify_password(req: PasswordRequest):
    return {"success": True, "message": "Access Granted"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)