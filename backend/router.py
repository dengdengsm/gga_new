import json
import os
from Agent import deepseek_agent
from rag import LocalKnowledgeBase
from typing import Dict, Any, List

class RouterAgent:
    def __init__(self, 
                 model_name: str = "deepseek-reasoner", 
                 learn_mode: bool = False,
                 experience_file: str = "./knowledge/experience/router.json"):
        
        print(f"--- åˆå§‹åŒ– RouterAgent (æ™ºèƒ½è¿›åŒ–ç‰ˆ) [æ¨¡åž‹: {model_name}] ---")
        self.llm = deepseek_agent(model_name=model_name)
        self.learn_mode = learn_mode
        self.experience_file = experience_file
        
        # 1. åˆå§‹åŒ– RAG å¼•æ“Ž (å¤ç”¨ LocalKnowledgeBase)
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å¤ç”¨ rag.py çš„èƒ½åŠ›ï¼Œå°†ç»éªŒæ± ä½œä¸º "QAçŸ¥è¯†" åŠ è½½
        self.rag = LocalKnowledgeBase("./.local_rag_db/router")
        
        # 2. åŠ è½½ç»éªŒ (å†·å¯åŠ¨)
        if os.path.exists(self.experience_file):
            print(f"ðŸ§  Router æ­£åœ¨åŠ è½½åŽ†å²ç»éªŒåº“: {self.experience_file}")
            # add_qa_mistakes æœ¬è´¨å°±æ˜¯åŠ è½½ list of {q, a}ï¼Œå®Œå…¨é€šç”¨
            # å®ƒä¼šè‡ªåŠ¨å¿½ç•¥ json é‡Œçš„ 'source_code' å­—æ®µï¼Œåªå­˜ q å’Œ a
            self.rag.add_qa_mistakes(self.experience_file)
        else:
            print("âš ï¸ æœªæ‰¾åˆ°ç»éªŒåº“æ–‡ä»¶ï¼ŒRouter å°†ä»Žé›¶å¼€å§‹è¿è¡Œã€‚")

    def _load_prompt(self, file_path: str) -> str:
        """åŠ è½½å¤–éƒ¨æç¤ºè¯æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            return ""

    def route_and_analyze(self, user_content: str, user_target:str = "",use_experience:bool = False) -> Dict[str, Any]:
        """
        æ ¸å¿ƒåŠŸèƒ½ï¼šåˆ†æžéœ€æ±‚ -> æ£€ç´¢ç»éªŒ -> åˆ¶å®šç­–ç•¥
        (å·²é‡æž„ï¼šå†…ç½® Promptï¼Œä¸å†ä¾èµ–å¤–éƒ¨æ–‡ä»¶ï¼Œç»Ÿä¸€ç®¡ç†å‚æ•°)
        """
        print(f"âš¡ Router æ­£åœ¨åˆ†æžéœ€æ±‚ (å­¦ä¹ æ¨¡å¼: {'å¼€å¯' if self.learn_mode else 'å…³é—­'})...")

     
        # 2. æž„å»ºç»éªŒä¸Šä¸‹æ–‡ (Dynamic RAG Section)
        
        experience_section = ""
        if use_experience:
            retrieved_experiences = self.rag.search_score(query=user_target, top_k=10)
            if retrieved_experiences:
                print(f"   [RAG] è”æƒ³åˆ° {len(retrieved_experiences)} æ¡ç›¸å…³è®¾è®¡æ€è·¯")
                
                # æ‹¼æŽ¥å…·ä½“ç»éªŒåˆ—è¡¨
                context_list = "\n".join([f"{idx+1}. {exp}" for idx, exp in enumerate(retrieved_experiences)])
                
                # æž„é€ ç»éªŒæŒ‡ä»¤å—
                experience_section = (
                    "\n\n"
                    "### ðŸ§  CRITICAL REFERENCE (RAG MEMORY)\n"
                    "The following are **SUCCESSFUL PAST STRATEGIES** retrieved from your memory bank.\n"
                    "**INSTRUCTION**: You MUST prioritized these strategies. If a past case used a specific diagram type for a similar scenario, **COPY THAT CHOICE**.\n"
                    "**Attention**: Pay more attention to the most popular strategies, for that is the most accepted, too.  "
                    "**The diagram type you choose should be suitable for the user's requirement:**\n"
                    "--------------------------------------------------\n"
                    f"{context_list}\n"
                )
            else:
                print("   [RAG] æ— ç›¸å…³ç»éªŒï¼Œä½¿ç”¨é€šç”¨ç­–ç•¥ã€‚")

        
        # 3. æž„é€ å®Œæ•´ System Prompt (åŽŸ router.md + åŠ¨æ€é€»è¾‘)
        # åŒ…å«äº†å›¾è¡¨ç±»åž‹æ˜ å°„è¡¨å’Œè¾“å‡ºæ ¼å¼è¦æ±‚
        system_prompt = (
    "You are a **Visual Logic Architect**. Your goal is to Analyze the User Request and Context, Select the Best Diagram Type, and **Extract Structured Logic** for the code generator.\n\n"
    
    "### 1. Analysis Strategy\n"
    "Step 1: Analyze the [User Content] to identify the core entities, relationships, and data flow.\n"
    "Step 2: Match the data characteristics with the **Diagram Type Menu**.\n"
    "Step 3: Extract **Critical Details** (Node names, edge labels, conditions, directions) into the `analysis_content`.\n\n"

    "### 2. Diagram Type Menu & Data Characteristics\n"
    "**Structure (Static Relationship)**:\n"
    "- `flowchart.md`: Decisions, process steps, algorithms. (Keyword: Process, Workflow, Logic)\n"
    "- `architecture.md`: System components, cloud infrastructure, container hierarchy. (Keyword: System, Layout, Stack)\n"
    "- `classDiagram.md`: OOP classes, inheritance, interfaces, attributes. (Keyword: Class, Object, Data Model)\n"
    "- `entityRelationshipDiagram.md`: Database schemas, PK/FK, cardinality. (Keyword: DB, Schema, Table)\n"
    
    "**Behavior (Dynamic Interaction)**:\n"
    "- `sequenceDiagram.md`: Message exchange sequence, API calls, request/response. (Keyword: Interaction, Protocol, Flow)\n"
    "- `stateDiagram.md`: Life-cycle states, state transitions, triggers. (Keyword: Status, State Machine, Lifecycle)\n"
    "- `userJourney.md`: User steps, satisfaction levels, tasks. (Keyword: User Experience, Step)\n\n"
    
    "**Data & Plan**:\n"
    "- `gantt.md`: Project schedules, dates, tasks. | `pie.md`: Proportions, percentages.\n\n"

    f"{experience_section}\n"

    "### 3. Critical Output Instruction for `analysis_content`\n"
    "The `analysis_content` MUST be a **Mermaid-Ready Logic Description**, NOT a general summary.\n"
    "- **If Flowchart**: List all nodes with clear IDs and text. Describe strictly: Node A -> Condition B -> Node C.\n"
    "- **If Sequence**: List participants clearly. Describe order: A calls B (sync/async), B returns to A.\n"
    "- **If Class/ER**: List Entity Names, Attributes (type/name), and specific relationships (1:N, inheritance).\n"
    "- **Keep Technical Terms**: Do not translate variable names or API endpoints.\n\n"

    "### 4. Output Format (JSON Only)\n"
    "{\n"
    "  \"reason\": \"Why you chose this diagram type (mention specific data features).\",\n"
    "  \"target_prompt_file\": \"filename.md\",\n"
    "  \"analysis_content\": \"Structured Logic Description...\"\n"
    "}"
)
        
        # 4. LLM å†³ç­–
        messages = [{"role": "user", "content": f"[User Requirement]:\n{user_target}\n\n[Context Content]:\n{user_content}"}]
        
        try:
            response_text = self.llm.chat(messages, system_prompt=system_prompt, json_mode=True)
            result = json.loads(response_text)
            
            # ç®€å•çš„åŽç¼€è¡¥å…¨
            if not result.get('target_prompt_file', '').endswith('.md'):
                result['target_prompt_file'] += ".md"
            
            return result
            
        except json.JSONDecodeError:
            print("Router JSON è§£æžå¤±è´¥ï¼Œå›žé€€é»˜è®¤ç­–ç•¥ã€‚")
            return {
                "target_prompt_file": "flowchart.md",
                "reason": "Fallback: JSON Parse Error",
                "analysis_content": user_content[:2000]
            }
        
    def analyze_specific_mode(self, user_content: str, user_target: str, specific_type: str, use_experience:bool = False) -> Dict[str, Any]:
        """
        ã€å®šå‘åˆ†æžæ¨¡å¼ - å¢žå¼ºç‰ˆã€‘
        æ”¯æŒ Graphviz (DOT) åŠ Mermaid çš„æ·±åº¦é€»è¾‘æå–ã€‚
        """
        print(f"âš¡ Router è¿›å…¥å®šå‘åˆ†æžæ¨¡å¼ -> ç›®æ ‡ç±»åž‹: {specific_type}")
        
        # 1. ç»éªŒæ£€ç´¢ (ä¿æŒåŽŸæœ‰é€»è¾‘ï¼Œå¢žå¼ºé’ˆå¯¹æ€§)
        experience_section = ""
        if use_experience:
            retrieved_experiences = self.rag.search_score(query=user_target, top_k=3)
            if retrieved_experiences:
                print(f"   [RAG] è”æƒ³åˆ° {len(retrieved_experiences)} æ¡ç›¸å…³ç»éªŒ")
                context_list = "\n".join([f"{idx+1}. {exp}" for idx, exp in enumerate(retrieved_experiences)])
                experience_section = (
                    "\n\n### ðŸ§  REFERENCE MEMORY (Past Success)\n"
                    f"Consider these successful patterns for {specific_type}:\n"
                    f"{context_list}\n"
                )

        # 2. æž„é€ æ–‡ä»¶å (è‡ªåŠ¨é€‚é… graphviz)
        # å¦‚æžœå‰ç«¯ä¼ çš„æ˜¯ 'dot' æˆ– 'graphviz'ï¼Œç»Ÿä¸€æ˜ å°„åˆ° graphviz.md
        if specific_type.lower() in ['dot', 'graphviz']:
            target_file = "graphviz.md"
            type_instruction = (
                "### SPECIAL INSTRUCTION FOR GRAPHVIZ (DOT)\n"
                "You are preparing logic for a **Graphviz DOT** engine.\n"
                "Focus on **Topology and Hierarchy** rather than just flow.\n"
                "**Extraction Requirements**:\n"
                "1. **Clusters/Subgraphs**: Group related nodes (e.g., 'subgraph cluster_A { ... }').\n"
                "2. **Node Attributes**: Define shapes (box, ellipse, record) based on entity type.\n"
                "3. **Relationships**: Define connections clearly (directed '->' or undirected '--').\n"
                "4. **Layout**: Suggest 'rankdir' (TB, LR) based on the flow.\n"
            )
        else:
            # Mermaid é€šç”¨é€»è¾‘
            target_file = f"{specific_type}.md" if specific_type.endswith('.md') else f"{specific_type}.md"
            type_instruction = (
                f"### SPECIAL INSTRUCTION FOR {specific_type.upper()}\n"
                "Focus on the strict syntax logic required for this specific Mermaid diagram type.\n"
                "- If Sequence: Identify Participants and exact Order of messages.\n"
                "- If Class/ER: Identify Entities, Attributes, and Cardinalities.\n"
                "- If Flowchart: Identify Nodes, Decisions, and Edge labels.\n"
            )

        # 3. æž„é€ å¢žå¼ºç‰ˆ System Prompt
        system_prompt = (
            f"You are a **Specialized Visual Logic Architect**.\n"
            f"The user has EXPLICITLY selected the tool: **'{specific_type}'**.\n"
            f"Your task is NOT to choose a tool, but to **Extract Structured Logic** specifically optimized for it.\n\n"
            
            f"{type_instruction}\n\n"
            
            f"{experience_section}\n\n"

            "### CRITICAL: Analysis Content Format\n"
            "The 'analysis_content' you output MUST be a **Structured Blueprint** for the code generator.\n"
            "Do NOT write paragraphs. Write logic steps or structural definitions.\n"
            "**Example for Graphviz**:\n"
            "- Layout: Left-to-Right (rankdir=LR)\n"
            "- Cluster 'Database': Contains [UserDB, LogDB]\n"
            "- Node 'App': shape=component\n"
            "- Edge: App -> UserDB [label='read']\n\n"

            "### OUTPUT FORMAT (JSON Only)\n"
            "{\n"
            f"  \"reason\": \"User manually selected {specific_type}. Analyzing for optimal structure.\",\n"
            f"  \"target_prompt_file\": \"{target_file}\",\n"
            f"  \"analysis_content\": \"...Your Structured Logic Blueprint here...\"\n"
            "}"
        )

        messages = [{"role": "user", "content": f"[User Requirement]: {user_target}\n\n[Context Content]:\n{user_content}"}]

        try:
            response_text = self.llm.chat(messages, system_prompt=system_prompt, json_mode=True)
            result = json.loads(response_text)
            
            # åŒé‡ä¿é™©ï¼šå¼ºåˆ¶è¦†ç›–æ–‡ä»¶åï¼Œé˜²æ­¢æ¨¡åž‹å¹»è§‰æ”¹å
            result['target_prompt_file'] = target_file
            
            return result
        except Exception as e:
            print(f"Router å®šå‘åˆ†æžå¤±è´¥: {e}ï¼Œä½¿ç”¨å›žé€€ç­–ç•¥")
            return {
                "target_prompt_file": target_file,
                "reason": "Fallback: Analysis Failed",
                "analysis_content": f"User Requirement: {user_target}\n\nContext Data:\n{user_content[:2000]}"
            }
                    
    def learn_from_success(self, user_query: str, valid_code: str):
        """
        ã€è¿›åŒ–æŽ¥å£ã€‘å½“ App ç¡®è®¤ä»£ç ç”ŸæˆæˆåŠŸåŽè°ƒç”¨ã€‚
        æç‚¼æœ¬æ¬¡æˆåŠŸçš„ {Q, A, Source} å¹¶å­˜å…¥åº“ã€‚
        """
        if not self.learn_mode:
            return

        print("ðŸ§  Router æ­£åœ¨ä»Žæœ¬æ¬¡æˆåŠŸæ¡ˆä¾‹ä¸­å­¦ä¹  (Experience Consolidation)...")
        
        # 1. LLM æç‚¼
        system_prompt = (
            "You are an Experience Extractor. Analyze the User Query and the Generated Mermaid Code.\n"
            "Extract a generic Experience Pair in JSON:\n"
            "{\n"
            "  \"q\": \"Abstract Scenario (e.g., Microservice Trace)\",\n"
            "  \"a\": \"Design Strategy (e.g., Use sequenceDiagram with activation bars...)\"\n"
            "}\n"
            "Note: 'q' should cover the intent, 'a' should cover the visualization technique."
        )
        
        user_msg = f"User Query:\n{user_query}\n\nGenerated Code:\n{valid_code[:1000]}..." # æˆªæ–­é˜²æ­¢å¤ªé•¿
        
        try:
            response = self.llm.chat([{"role": "user", "content": user_msg}], system_prompt=system_prompt, json_mode=True)
            data = json.loads(response)
            
            new_q = data.get("q")
            new_a = data.get("a")
            
            if new_q and new_a:
                # 2. æž„é€ å®Œæ•´è®°å½• (å«æºç æº¯æº)
                new_entry = {
                    "q": new_q,
                    "a": new_a,
                    "source_code": valid_code # ä¿ç•™æºç ä½œä¸ºæ¡ˆåº•
                }
                
                # 3. æŒä¹…åŒ–å­˜å‚¨ (JSON)
                self._save_to_disk(new_entry)
                
                # 4. è¿è¡Œæ—¶çƒ­æ›´æ–° (RAG)
                # åªéœ€è¦ q å’Œ a å³å¯æ£€ç´¢
                self.rag.add_single_qa(new_q, new_a, source="runtime_learning")
                print(f"âœ¨ Router ç»éªŒå€¼ +1: {new_q}")
                
        except Exception as e:
            print(f"Router å­¦ä¹ å¤±è´¥: {e}")

    def _save_to_disk(self, new_entry: Dict[str, Any]):
        """è¿½åŠ å†™å…¥ JSON æ–‡ä»¶"""
        current_data = []
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(self.experience_file), exist_ok=True)
        
        if os.path.exists(self.experience_file):
            try:
                with open(self.experience_file, 'r', encoding='utf-8') as f:
                    current_data = json.load(f)
            except:
                current_data = []
        
        # ç®€å•çš„æŸ¥é‡ (åŸºäºŽ Q)
        # å®žé™…ç”Ÿäº§ä¸­å¯èƒ½å…è®¸åŒä¸€ä¸ª Q æœ‰å¤šç§ Aï¼Œè¿™é‡Œç®€å•èµ·è§åŽ»é‡
        for item in current_data:
            if item.get('q') == new_entry['q']:
                return # å·²å­˜åœ¨ç±»ä¼¼åœºæ™¯ï¼Œæš‚ä¸é‡å¤å½•å…¥

        current_data.append(new_entry)
        
        with open(self.experience_file, 'w', encoding='utf-8') as f:
            json.dump(current_data, f, ensure_ascii=False, indent=2)
    def reload_llm_config(self, config: dict):
        """
        ã€çƒ­æ›´æ–°ã€‘æŽ¥æ”¶å‰ç«¯é…ç½®(é©¼å³°å‘½å)å¹¶æ›´æ–°åº•å±‚ LLM
        """
        # ä»Žå­—å…¸ä¸­æå–é…ç½®
        api_key = config.get("apiKey")
        api_url = config.get("apiUrl")
        model_name = config.get("modelName")
        
        # è°ƒç”¨åº•å±‚ Agent.py ä¸­å®šä¹‰çš„ update_config
        # è¿™é‡Œçš„ self.llm å¯¹åº” Agent/deepseek_agent å®žä¾‹
        if hasattr(self, 'llm'):
            self.llm.update_config(api_key=api_key, base_url=api_url, model_name=model_name)
            print(f"ðŸ”„ [{self.__class__.__name__}] LLMé…ç½®å·²é‡è½½ -> æ¨¡åž‹: {model_name}")

# --- å•å…ƒæµ‹è¯• ---
if __name__ == "__main__":
    # æµ‹è¯•åˆå§‹åŒ–
    router = RouterAgent(learn_mode=True)
    
    # æµ‹è¯•åˆ†æž
    req = "ç”»ä¸€ä¸ªTCPä¸‰æ¬¡æ¡æ‰‹çš„æ—¶åºå›¾"
    res = router.route_and_analyze(req)
    print("åˆ†æžç»“æžœ:", res.get("target_prompt_file"))
    
    # æµ‹è¯•å­¦ä¹ 
    code = "sequenceDiagram\nClient->>Server: SYN\nServer->>Client: SYN, ACK..."
    router.learn_from_success(req, code)